{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T21:24:30.988055Z",
     "start_time": "2019-09-17T21:24:28.898515Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from random import shuffle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "\n",
    "import spacy\n",
    "\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset, Iterator\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_lightning as ptl\n",
    "from test_tube import Experiment\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from millenlp.embeddings import FastTextVec\n",
    "\n",
    "from bokeh.plotting import figure, output_notebook, show, ColumnDataSource, output_file\n",
    "from bokeh.palettes import Blues9,Spectral11,Category10,Set1,Set2,Category20\n",
    "from bokeh.io import reset_output\n",
    "from bokeh.models import BoxSelectTool,CustomJS, ColumnDataSource, Legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T21:24:30.997571Z",
     "start_time": "2019-09-17T21:24:30.990031Z"
    }
   },
   "outputs": [],
   "source": [
    "output_file(\"Cluster.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T21:24:38.710091Z",
     "start_time": "2019-09-17T21:24:38.691349Z"
    },
    "code_folding": [
     0,
     35
    ]
   },
   "outputs": [],
   "source": [
    "def preping_bokeh_clustering(original_data,features,column,cluster):\n",
    "    \n",
    "    color_dic = {}\n",
    "    L = cluster['ClusterNumber'].unique().shape[0]\n",
    "    nums = [x for x in range(L)]\n",
    "    shuffle(nums)\n",
    "    if L <= 20:\n",
    "        for k,value in enumerate(cluster['ClusterNumber'].unique()):\n",
    "            if L >10:\n",
    "                color_dic[value] = Category20[20][nums[k]]\n",
    "            else:\n",
    "                color_dic[value] = Category10[10][nums[k]]\n",
    "    else:\n",
    "            \n",
    "        hexa = ['0','1','2','3','4','5','6','7','8','9','a','b','c','d','e','f']\n",
    "        color_dic = {}\n",
    "        for k,value in enumerate(cluster['ClusterNumber'].unique()):\n",
    "            color_dic[value] = ''.join([choice(hexa) if i != 0 else '#' for i in range(7)])\n",
    "\n",
    "    df_bokeh = pd.DataFrame(np.concatenate((features,\n",
    "                                            original_data[column].values.reshape(-1,1),\n",
    "                                            original_data['lemma'].values.reshape(-1,1),\n",
    "                                            cluster['ClusterNumber'].values.reshape(-1,1)),axis=1),\n",
    "\n",
    "                            columns=['x','y','Message','lemma','Label'])\n",
    "    \n",
    "    df_bokeh['color'] = cluster.ClusterNumber.apply(lambda x: color_dic[x])\n",
    "    \n",
    "    TOOLTIPS = [(\"Index\", \"$index\"),\n",
    "            (\"(x,y)\", \"(@x, @y)\"),\n",
    "            (\"Message\", \"@{Message}\"),\n",
    "            (\"Lemmas\", \"@{lemma}\"),\n",
    "            (\"Label\", \"@{Label}\")]\n",
    "\n",
    "    return df_bokeh, TOOLTIPS\n",
    "\n",
    "def scatter(source,TOOLTIPS,classes):\n",
    "    p = figure(title=\"Fasttext and TSNE\", \n",
    "           x_axis_label='x', y_axis_label='y',\n",
    "           plot_width=950, plot_height=500, \n",
    "           tools = 'lasso_select,box_zoom,pan,poly_select,tap,wheel_zoom,save,zoom_out,crosshair,hover,reset,help',\n",
    "           tooltips=TOOLTIPS)\n",
    "    \n",
    "    legend_it = []\n",
    "    cluster_size = []\n",
    "    for label in range(0,classes):\n",
    "        cluster_size.append((label,source[source['Label']==label].shape[0]))\n",
    "    cluster_size = sorted(cluster_size, key = lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for label in list(np.array(cluster_size)[:,0]):\n",
    "        c = p.scatter(x = \"x\",y = \"y\",size=5,\n",
    "                      line_color=\"black\", color=\"color\", \n",
    "                      alpha=0.7, source=ColumnDataSource(source[source['Label']==label]))\n",
    "        legend_it.append((str(label), [c]))\n",
    "    \n",
    "    legend = Legend(items=legend_it, location=(0, -30), spacing = 1)\n",
    "    legend.click_policy=\"hide\"\n",
    "    p.add_layout(legend, 'right')\n",
    "    \n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder with pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T21:24:48.588762Z",
     "start_time": "2019-09-17T21:24:48.582035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda: 0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T21:24:49.446367Z",
     "start_time": "2019-09-17T21:24:49.442161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T21:24:50.071018Z",
     "start_time": "2019-09-17T21:24:50.068222Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T21:24:50.253595Z",
     "start_time": "2019-09-17T21:24:50.248532Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('dataset/data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T22:53:11.551238Z",
     "start_time": "2019-08-22T22:53:08.134Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, test_size=0.30)\n",
    "data_val, data_test = train_test_split(data_test, test_size=0.5)\n",
    "data_train.shape, data_val.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T22:53:11.552062Z",
     "start_time": "2019-08-22T22:53:08.667Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train.to_csv('dataset/data_train.csv')\n",
    "data_val.to_csv('dataset/data_val.csv')\n",
    "data_test.to_csv('dataset/data_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataset Clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T21:25:07.577791Z",
     "start_time": "2019-09-17T21:24:52.973542Z"
    }
   },
   "outputs": [],
   "source": [
    "spacy_es = spacy.load('es_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T21:25:07.583636Z",
     "start_time": "2019-09-17T21:25:07.579888Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    \"\"\"\n",
    "    Tokenizes Spanish text from a string into a list of strings (tokens) and reverses it\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_es.tokenizer(text)][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T21:25:07.593573Z",
     "start_time": "2019-09-17T21:25:07.585861Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_dataset(fix_length=100, lower=False, vectors=None):\n",
    "    if vectors is not None:\n",
    "        # pretrain vectors only supports all lower cases\n",
    "        lower = True\n",
    "        \n",
    "    comment = Field(\n",
    "        sequential=True,\n",
    "        init_token = '<sos>',\n",
    "        eos_token = '<eos>',\n",
    "        fix_length=fix_length,\n",
    "        tokenize=tokenizer,\n",
    "        pad_first=False,\n",
    "        batch_first = True,\n",
    "        lower=lower\n",
    "    )\n",
    "    train, val = TabularDataset.splits(\n",
    "        path='dataset/', format='csv', skip_header=True,\n",
    "        train='data_train.csv', validation='data_val.csv',\n",
    "        fields=[\n",
    "            ('mensaje', None),\n",
    "            ('lemma', comment),\n",
    "            ('cluster', None),\n",
    "            ('cluster_2', None),\n",
    "            ('output', comment)\n",
    "        ])\n",
    "    test = TabularDataset(\n",
    "        path='dataset/data_test.csv', format='csv', \n",
    "        skip_header=True,\n",
    "        fields=[\n",
    "            ('mensaje', None),\n",
    "            ('lemma', comment),\n",
    "            ('cluster', None),\n",
    "            ('cluster_2', None)\n",
    "        ])\n",
    "\n",
    "    comment.build_vocab(\n",
    "        train, val, test,\n",
    "        max_size=7000,\n",
    "        min_freq=10,\n",
    "        vectors=vectors\n",
    "    )\n",
    "    return train, val, test, comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T21:25:39.309200Z",
     "start_time": "2019-09-17T21:25:07.595774Z"
    }
   },
   "outputs": [],
   "source": [
    "sequence_length = 50\n",
    "train_dataset, val_dataset, test_dataset, message_field = get_dataset(fix_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T14:22:53.848756Z",
     "start_time": "2019-09-12T14:22:53.846563Z"
    }
   },
   "outputs": [],
   "source": [
    "generator = BucketIterator(train_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T14:22:53.951361Z",
     "start_time": "2019-09-12T14:22:53.850603Z"
    }
   },
   "outputs": [],
   "source": [
    "examples = generator.data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T21:25:39.327663Z",
     "start_time": "2019-09-17T21:25:39.311742Z"
    },
    "code_folding": [
     0,
     1,
     32,
     39
    ]
   },
   "outputs": [],
   "source": [
    "class Encoder(ptl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 layers, \n",
    "                 hidden_size, \n",
    "                 input_size, \n",
    "                 message_field, \n",
    "                 dropout = 0, \n",
    "                 bidir = False, \n",
    "                 batch_size = 256):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers = layers\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout = dropout\n",
    "        self.bidir = bidir\n",
    "        self.message_field = message_field\n",
    "        self.embedding_dim = input_size\n",
    "        \n",
    "        self.word_embedding = nn.Embedding(num_embeddings=len(self.message_field.vocab.itos),\n",
    "                                           embedding_dim=self.embedding_dim,\n",
    "                                           padding_idx=self.message_field.vocab.stoi['<pad>']).to(DEVICE)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim,\n",
    "                                  hidden_size=self.hidden_size,\n",
    "                                  num_layers=self.layers,\n",
    "                                  batch_first=True,\n",
    "                                  dropout = self.dropout if self.dropout and self.layers > 1 else 0,\n",
    "                                  bidirectional = self.bidir).to(DEVICE)\n",
    "        \n",
    "        self.init_weigths()\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        # the weights are of the form (nb_layers, batch_size, nb_lstm_units)\n",
    "        hidden = torch.randn(self.layers*2 if self.bidir else self.layers, batch_size, self.hidden_size).to(DEVICE)\n",
    "        cell = torch.randn(self.layers*2 if self.bidir else self.layers, batch_size, self.hidden_size).to(DEVICE)\n",
    "\n",
    "        return (hidden, cell)\n",
    "    \n",
    "    def init_weigths(self):\n",
    "        \n",
    "        for param in self.lstm.named_parameters():\n",
    "            if 'weight' in param[0]:\n",
    "                torch.nn.init.xavier_normal_(param[1])\n",
    "#         torch.nn.init.xavier_normal_(self.dense.weight)\n",
    "        print('weigths initializer: done!')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.word_embedding(x)\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        self.hidden, self.cell = self.init_hidden(batch_size)\n",
    "        x, (self.hidden, self.cell) = self.lstm(x, (self.hidden, self.cell))\n",
    "        \n",
    "        return self.hidden, self.cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T21:25:39.346704Z",
     "start_time": "2019-09-17T21:25:39.329606Z"
    },
    "code_folding": [
     0,
     1,
     46,
     53,
     62
    ]
   },
   "outputs": [],
   "source": [
    "class Decoder(ptl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 layers, \n",
    "                 hidden_size, \n",
    "                 input_size,\n",
    "                 out_dim,\n",
    "                 message_field,\n",
    "                 dropout = 0, \n",
    "                 bidir = False, \n",
    "                 batch_size = 256,\n",
    "                 sequence_length = 100):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers = layers\n",
    "        self.input_size = input_size\n",
    "        self.output_dim = out_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout = dropout\n",
    "        self.bidir = bidir\n",
    "        self.sequence_length = sequence_length\n",
    "        self.message_field = message_field\n",
    "        \n",
    "        self.word_embedding = nn.Embedding(num_embeddings = self.output_dim, \n",
    "                                           embedding_dim = self.input_size,\n",
    "                                           padding_idx=self.message_field.vocab.stoi['<pad>'])\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=self.input_size,\n",
    "                            hidden_size=self.hidden_size,\n",
    "                            num_layers=self.layers,\n",
    "                            batch_first=True,\n",
    "                            dropout = self.dropout if self.dropout and self.layers > 1 else 0,\n",
    "                            bidirectional = self.bidir).to(DEVICE)\n",
    "        \n",
    "        self.linear1 = torch.nn.Linear(self.hidden_size*2 if self.bidir else self.hidden_size, \n",
    "                                       1024).to(DEVICE)\n",
    "        \n",
    "        self.bn = torch.nn.BatchNorm1d(num_features=1024).to(DEVICE)\n",
    "        self.dropout = torch.nn.Dropout(self.dropout)\n",
    "        \n",
    "        self.linear2 = torch.nn.Linear(1024, self.output_dim).to(DEVICE)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        self.init_weigths()\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        # the weights are of the form (nb_layers, batch_size, nb_lstm_units)\n",
    "        hidden = torch.randn(self.layers*2 if self.bidir else self.layers, batch_size, self.hidden_size).to(DEVICE)\n",
    "        cell = torch.randn(self.layers*2 if self.bidir else self.layers, batch_size, self.hidden_size).to(DEVICE)\n",
    "\n",
    "        return (hidden, cell)\n",
    "    \n",
    "    def init_weigths(self):\n",
    "        \n",
    "        for param in self.lstm.named_parameters():\n",
    "            if 'weight' in param[0]:\n",
    "                torch.nn.init.xavier_normal_(param[1])\n",
    "        torch.nn.init.xavier_normal_(self.linear1.weight)\n",
    "        torch.nn.init.xavier_normal_(self.linear2.weight)\n",
    "        print('weigths initializer: done!')\n",
    "    \n",
    "    def outReshape(self, last_hidden):\n",
    "        \n",
    "        last_hidden = last_hidden.view(self.layers,2,-1,self.hidden_size)[-1] if self.bidir else last_hidden[-1]\n",
    "        last_hidden = last_hidden.contiguous()\n",
    "        last_hidden = last_hidden.view(-1, self.hidden_size*2 if self.bidir else self.hidden_size)\n",
    "        \n",
    "        return last_hidden\n",
    "        \n",
    "    def forward(self, x, encoder_hidden, encoder_cell):\n",
    "        \n",
    "        x = self.word_embedding(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        x, (decoder_hidden, decoder_cell) = self.lstm(x, (encoder_hidden, encoder_cell))\n",
    "        \n",
    "        x = x.view(-1,self.sequence_length,2,self.hidden_size) if self.bidir else x\n",
    "        \n",
    "        decoder_hidden = self.outReshape(decoder_hidden)\n",
    "        decoder_cell = self.outReshape(decoder_cell)\n",
    "        \n",
    "        output = self.dropout(F.relu(self.linear1(x)))\n",
    "        output = self.softmax(self.linear2(output))\n",
    "        \n",
    "        return output, (decoder_hidden, decoder_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T21:25:39.369468Z",
     "start_time": "2019-09-17T21:25:39.349439Z"
    },
    "code_folding": [
     0,
     1,
     39,
     80
    ]
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(ptl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 layers, \n",
    "                 hidden_size, \n",
    "                 input_size, \n",
    "                 message_field, \n",
    "                 dropout = 0, \n",
    "                 bidir = False, \n",
    "                 batch_size = 256,\n",
    "                 sequence_length = 100):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.hidden_size = hidden_size\n",
    "        self.message_field = message_field\n",
    "        self.output_dim = len(self.message_field.vocab.itos)\n",
    "\n",
    "        self.encoder = Encoder(layers = layers, \n",
    "                               hidden_size = self.hidden_size, \n",
    "                               input_size = input_size,\n",
    "                               message_field =  self.message_field,\n",
    "                               dropout = dropout, \n",
    "                               bidir = bidir, \n",
    "                               batch_size = batch_size).to(DEVICE)\n",
    "        \n",
    "        self.decoder = Decoder(layers = layers, \n",
    "                               hidden_size = self.hidden_size, \n",
    "                               input_size = input_size,\n",
    "                               out_dim = self.output_dim,\n",
    "                               message_field =  self.message_field,\n",
    "                               dropout = dropout, \n",
    "                               bidir = bidir, \n",
    "                               batch_size = batch_size,\n",
    "                               sequence_length = self.sequence_length).to(DEVICE)\n",
    "        \n",
    "        self.loss = torch.nn.CrossEntropyLoss(ignore_index = self.message_field.vocab.stoi['<pad>'],\n",
    "                                             reduction = 'mean')\n",
    "        \n",
    "    def forward(self, x, y, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        ## The padding index is 1 with the token <pad>\n",
    "        outputs = torch.ones(batch_size, self.sequence_length, self.output_dim).to(DEVICE)\n",
    "        \n",
    "        encoder_hidden, encoder_cell = self.encoder(x)\n",
    "        \n",
    "        decoder_input = torch.ones((batch_size,), dtype=torch.long, device=DEVICE)\n",
    "        decoder_input.new_full((batch_size, ), self.message_field.vocab.stoi['<sos>'])\n",
    "        \n",
    "        for step in range(self.sequence_length):\n",
    "            output, (hidden, cell) = self.decoder(decoder_input, encoder_hidden, encoder_cell)\n",
    "            output = output.squeeze(1)\n",
    "            outputs[:, step, :] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top_word = output.max(1)[1]\n",
    "            decoder_input = (y[:, step] if teacher_force else top_word)\n",
    "#             if teacher_force:\n",
    "#                 print('True - {}'.format(self.message_field.vocab.itos[decoder_input[0]]))\n",
    "#             else:\n",
    "#                 print('False - {}'.format(self.message_field.vocab.itos[decoder_input[0]]))\n",
    "                \n",
    "        return outputs\n",
    "    \n",
    "    def my_loss(self, y_hat, y):\n",
    "        y = y[:,1:].contiguous().view(-1)\n",
    "        y_hat = y_hat[:,1:,:].contiguous().view(-1, y_hat.shape[-1])\n",
    "        return self.loss(y_hat, y)\n",
    "    \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        (x, y), _ = batch\n",
    "        y_hat = self.forward(x, y)\n",
    "        return {'loss': self.my_loss(y_hat, y)}\n",
    "    \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        (x, y), _ = batch\n",
    "        y_hat = self.forward(x, y)\n",
    "        return {'val_loss': self.my_loss(y_hat, y)}\n",
    "    \n",
    "    def validation_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        return {'avg_val_loss': avg_loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return [torch.optim.Adam(self.parameters(), lr=0.1, weight_decay=5e-4, amsgrad = True)]\n",
    "    \n",
    "    @ptl.data_loader\n",
    "    def tng_dataloader(self):\n",
    "        return BucketIterator(train_dataset, batch_size=self.batch_size, device=DEVICE)\n",
    "\n",
    "    @ptl.data_loader\n",
    "    def val_dataloader(self):\n",
    "        return BucketIterator(val_dataset, batch_size=self.batch_size, device=DEVICE)\n",
    "    \n",
    "    @ptl.data_loader\n",
    "    def test_dataloader(self):\n",
    "        return BucketIterator(test_dataset, batch_size=self.batch_size, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T21:25:42.363415Z",
     "start_time": "2019-09-17T21:25:42.280634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weigths initializer: done!\n",
      "weigths initializer: done!\n",
      "VISIBLE GPUS: '0'\n",
      "gpu available: True, used: True\n"
     ]
    }
   ],
   "source": [
    "model = AutoEncoder(layers = 2,\n",
    "                    hidden_size = 400,\n",
    "                    input_size = 100,\n",
    "                    message_field = message_field,\n",
    "                    dropout = 0.2,\n",
    "                    bidir = False,\n",
    "                    batch_size=256,\n",
    "                    sequence_length = sequence_length)\n",
    "\n",
    "exp = Experiment(save_dir=os.getcwd())\n",
    "trainer = ptl.Trainer(experiment=exp, max_nb_epochs=100, train_percent_check=0.1, gpus=[0],track_grad_norm=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T22:30:25.217217Z",
     "start_time": "2019-09-17T21:25:42.364595Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Name              Type   Params\n",
      "0                  encoder           Encoder  2679100\n",
      "1   encoder.word_embedding         Embedding   592700\n",
      "2             encoder.lstm              LSTM  2086400\n",
      "3                  decoder           Decoder  9166947\n",
      "4   decoder.word_embedding         Embedding   592700\n",
      "5             decoder.lstm              LSTM  2086400\n",
      "6          decoder.linear1            Linear   410624\n",
      "7               decoder.bn       BatchNorm1d     2048\n",
      "8          decoder.dropout           Dropout        0\n",
      "9          decoder.linear2            Linear  6075175\n",
      "10         decoder.softmax           Softmax        0\n",
      "11                    loss  CrossEntropyLoss        0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "119it [00:39,  3.88it/s, avg_val_loss=8.69, batch_nb=37, epoch=99, gpu=0, loss=8.687, v_nb=139]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View tensorboard logs by running\n",
      "tensorboard --logdir /home/daniel/Deep_RNN/AutoEncoders\n",
      "and going to http://localhost:6006 on your browser\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)\n",
    "\n",
    "# view tensorflow logs \n",
    "print(f'View tensorboard logs by running\\ntensorboard --logdir {os.getcwd()}')\n",
    "print('and going to http://localhost:6006 on your browser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Dimentionality Reduction with the Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to Extract Features from encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:29:16.853325Z",
     "start_time": "2019-09-06T17:29:16.848545Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getEncoderFeatures(text):\n",
    "    model.eval()\n",
    "    out = model.encoder(torch.LongTensor([[message_field.vocab.stoi[word] for word in tokenizer(text)]]).to(DEVICE))\n",
    "    return out.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:29:20.274689Z",
     "start_time": "2019-09-06T17:29:20.269589Z"
    }
   },
   "outputs": [],
   "source": [
    "def getEmbeddingFeatures(text):\n",
    "    model.eval()\n",
    "    out = model.encoder.word_embedding(torch.LongTensor([[message_field.vocab.stoi[word] for word in tokenizer(text)]]).to(DEVICE))\n",
    "    return out.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:44:28.350155Z",
     "start_time": "2019-09-06T17:44:18.993915Z"
    }
   },
   "outputs": [],
   "source": [
    "data2plot = pd.read_excel('dataset/data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Features from Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:46:18.069415Z",
     "start_time": "2019-09-06T17:44:42.668467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136915, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_AE = np.array([getEncoderFeatures(text) for text in data2plot.lemma.tolist()]).squeeze(1)\n",
    "features_AE.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Features from Encoder Word Embedding to Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:58:14.009470Z",
     "start_time": "2019-09-06T17:57:37.647045Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136915, 300)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.array([getEmbeddingFeatures(text).squeeze(0).mean(0) for text in data2plot.lemma])\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:59:19.985869Z",
     "start_time": "2019-09-06T17:58:28.696752Z"
    }
   },
   "outputs": [],
   "source": [
    "#BGM = BayesianGaussianMixture(n_components=20, covariance_type='full', max_iter=100).fit(features)\n",
    "kmeans = KMeans(n_clusters=20).fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:59:20.185462Z",
     "start_time": "2019-09-06T17:59:19.987553Z"
    }
   },
   "outputs": [],
   "source": [
    "cluster = pd.DataFrame(kmeans.predict(features), columns = ['ClusterNumber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-06T17:59:49.403150Z",
     "start_time": "2019-09-06T17:59:46.864191Z"
    }
   },
   "outputs": [],
   "source": [
    "source, TOOLTIPS = preping_bokeh_clustering(data2plot,\n",
    "                                            features_AE,\n",
    "                                            'mensaje',\n",
    "                                            cluster)\n",
    "scatter(source,TOOLTIPS,len(cluster.ClusterNumber.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T21:27:37.965045Z",
     "start_time": "2019-09-04T21:26:36.098Z"
    }
   },
   "outputs": [],
   "source": [
    "# data2cluster = data2cluster.drop(columns = ['cluster'])\n",
    "data2cluster['cluster'] = cluster.ClusterNumber.tolist()\n",
    "\n",
    "data2cluster.to_excel('Conversaciones_Chat_Codensa_2019_onlyUser_cluster_fix3_kmeans.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
